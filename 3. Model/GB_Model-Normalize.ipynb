{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f972c5af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b52704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9a5c4f",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1793bef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZABT</th>\n",
       "      <th>ZATT</th>\n",
       "      <th>ZSFH</th>\n",
       "      <th>RSNA</th>\n",
       "      <th>NYTPOP</th>\n",
       "      <th>ACTLISCOU35620</th>\n",
       "      <th>NEWLISCOU35620</th>\n",
       "      <th>PENLISCOU35620</th>\n",
       "      <th>PRIREDCOU35620</th>\n",
       "      <th>NEWY636BPPRIV</th>\n",
       "      <th>...</th>\n",
       "      <th>CUURA101SAR</th>\n",
       "      <th>CUURA101SAF116</th>\n",
       "      <th>CUURA101SAA</th>\n",
       "      <th>CUURA101SANL1</th>\n",
       "      <th>CUURA101SS47016</th>\n",
       "      <th>PSAVERT</th>\n",
       "      <th>MICH</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>T10Y2Y</th>\n",
       "      <th>T10Y3M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>263665.000000</td>\n",
       "      <td>7.639080e+05</td>\n",
       "      <td>421874.000000</td>\n",
       "      <td>2515.697593</td>\n",
       "      <td>19336.456</td>\n",
       "      <td>71440.0</td>\n",
       "      <td>21816.0</td>\n",
       "      <td>9263.0</td>\n",
       "      <td>12840.0</td>\n",
       "      <td>2939.0</td>\n",
       "      <td>...</td>\n",
       "      <td>118.985</td>\n",
       "      <td>254.813</td>\n",
       "      <td>121.576</td>\n",
       "      <td>178.913</td>\n",
       "      <td>194.696</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-30</th>\n",
       "      <td>264317.000000</td>\n",
       "      <td>7.653900e+05</td>\n",
       "      <td>422882.000000</td>\n",
       "      <td>2517.262497</td>\n",
       "      <td>19336.456</td>\n",
       "      <td>69427.0</td>\n",
       "      <td>17092.0</td>\n",
       "      <td>9077.0</td>\n",
       "      <td>11850.0</td>\n",
       "      <td>4275.0</td>\n",
       "      <td>...</td>\n",
       "      <td>119.552</td>\n",
       "      <td>254.393</td>\n",
       "      <td>129.847</td>\n",
       "      <td>180.747</td>\n",
       "      <td>188.480</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-31</th>\n",
       "      <td>265031.000000</td>\n",
       "      <td>7.670250e+05</td>\n",
       "      <td>423987.000000</td>\n",
       "      <td>2512.303863</td>\n",
       "      <td>19336.456</td>\n",
       "      <td>67715.0</td>\n",
       "      <td>19382.0</td>\n",
       "      <td>8934.0</td>\n",
       "      <td>12878.0</td>\n",
       "      <td>4258.0</td>\n",
       "      <td>...</td>\n",
       "      <td>119.874</td>\n",
       "      <td>254.879</td>\n",
       "      <td>133.232</td>\n",
       "      <td>183.620</td>\n",
       "      <td>190.183</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-30</th>\n",
       "      <td>265862.000000</td>\n",
       "      <td>7.689390e+05</td>\n",
       "      <td>425312.000000</td>\n",
       "      <td>2507.025158</td>\n",
       "      <td>19336.456</td>\n",
       "      <td>66569.0</td>\n",
       "      <td>16736.0</td>\n",
       "      <td>8943.0</td>\n",
       "      <td>11808.0</td>\n",
       "      <td>2559.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.142</td>\n",
       "      <td>255.126</td>\n",
       "      <td>130.743</td>\n",
       "      <td>183.239</td>\n",
       "      <td>192.314</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>266632.000000</td>\n",
       "      <td>7.709340e+05</td>\n",
       "      <td>426762.000000</td>\n",
       "      <td>2496.784727</td>\n",
       "      <td>19336.456</td>\n",
       "      <td>62162.0</td>\n",
       "      <td>15042.0</td>\n",
       "      <td>9062.0</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>3483.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121.092</td>\n",
       "      <td>256.281</td>\n",
       "      <td>124.428</td>\n",
       "      <td>182.221</td>\n",
       "      <td>202.140</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-31</th>\n",
       "      <td>409337.000000</td>\n",
       "      <td>1.016134e+06</td>\n",
       "      <td>624836.000000</td>\n",
       "      <td>3131.359562</td>\n",
       "      <td>19768.458</td>\n",
       "      <td>39687.0</td>\n",
       "      <td>18358.0</td>\n",
       "      <td>18632.0</td>\n",
       "      <td>8096.0</td>\n",
       "      <td>3438.0</td>\n",
       "      <td>...</td>\n",
       "      <td>141.277</td>\n",
       "      <td>296.748</td>\n",
       "      <td>133.312</td>\n",
       "      <td>214.066</td>\n",
       "      <td>313.305</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.56</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30</th>\n",
       "      <td>410536.000000</td>\n",
       "      <td>1.020136e+06</td>\n",
       "      <td>625394.000000</td>\n",
       "      <td>3099.155451</td>\n",
       "      <td>19768.458</td>\n",
       "      <td>40049.0</td>\n",
       "      <td>14664.0</td>\n",
       "      <td>17675.0</td>\n",
       "      <td>8752.0</td>\n",
       "      <td>2718.0</td>\n",
       "      <td>...</td>\n",
       "      <td>144.058</td>\n",
       "      <td>298.499</td>\n",
       "      <td>129.743</td>\n",
       "      <td>213.962</td>\n",
       "      <td>304.637</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>410411.000000</td>\n",
       "      <td>1.019711e+06</td>\n",
       "      <td>624669.000000</td>\n",
       "      <td>3075.999271</td>\n",
       "      <td>19768.458</td>\n",
       "      <td>38650.0</td>\n",
       "      <td>11362.0</td>\n",
       "      <td>16282.0</td>\n",
       "      <td>7498.0</td>\n",
       "      <td>3549.0</td>\n",
       "      <td>...</td>\n",
       "      <td>142.249</td>\n",
       "      <td>299.317</td>\n",
       "      <td>123.985</td>\n",
       "      <td>215.400</td>\n",
       "      <td>323.524</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.78</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>-0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31</th>\n",
       "      <td>410105.000000</td>\n",
       "      <td>1.019926e+06</td>\n",
       "      <td>623959.000000</td>\n",
       "      <td>3068.361445</td>\n",
       "      <td>19768.458</td>\n",
       "      <td>33983.0</td>\n",
       "      <td>7348.0</td>\n",
       "      <td>14434.0</td>\n",
       "      <td>3820.0</td>\n",
       "      <td>4438.0</td>\n",
       "      <td>...</td>\n",
       "      <td>142.202</td>\n",
       "      <td>302.110</td>\n",
       "      <td>122.084</td>\n",
       "      <td>208.488</td>\n",
       "      <td>302.990</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.10</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28</th>\n",
       "      <td>381016.902142</td>\n",
       "      <td>9.573259e+05</td>\n",
       "      <td>601538.479252</td>\n",
       "      <td>3083.935335</td>\n",
       "      <td>19768.458</td>\n",
       "      <td>30697.0</td>\n",
       "      <td>11128.0</td>\n",
       "      <td>12921.0</td>\n",
       "      <td>4626.0</td>\n",
       "      <td>2583.0</td>\n",
       "      <td>...</td>\n",
       "      <td>144.241</td>\n",
       "      <td>302.161</td>\n",
       "      <td>132.814</td>\n",
       "      <td>212.719</td>\n",
       "      <td>297.364</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.33</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-1.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ZABT          ZATT           ZSFH         RSNA  \\\n",
       "date                                                                  \n",
       "2016-08-31  263665.000000  7.639080e+05  421874.000000  2515.697593   \n",
       "2016-09-30  264317.000000  7.653900e+05  422882.000000  2517.262497   \n",
       "2016-10-31  265031.000000  7.670250e+05  423987.000000  2512.303863   \n",
       "2016-11-30  265862.000000  7.689390e+05  425312.000000  2507.025158   \n",
       "2016-12-31  266632.000000  7.709340e+05  426762.000000  2496.784727   \n",
       "...                   ...           ...            ...          ...   \n",
       "2022-10-31  409337.000000  1.016134e+06  624836.000000  3131.359562   \n",
       "2022-11-30  410536.000000  1.020136e+06  625394.000000  3099.155451   \n",
       "2022-12-31  410411.000000  1.019711e+06  624669.000000  3075.999271   \n",
       "2023-01-31  410105.000000  1.019926e+06  623959.000000  3068.361445   \n",
       "2023-02-28  381016.902142  9.573259e+05  601538.479252  3083.935335   \n",
       "\n",
       "               NYTPOP  ACTLISCOU35620  NEWLISCOU35620  PENLISCOU35620  \\\n",
       "date                                                                    \n",
       "2016-08-31  19336.456         71440.0         21816.0          9263.0   \n",
       "2016-09-30  19336.456         69427.0         17092.0          9077.0   \n",
       "2016-10-31  19336.456         67715.0         19382.0          8934.0   \n",
       "2016-11-30  19336.456         66569.0         16736.0          8943.0   \n",
       "2016-12-31  19336.456         62162.0         15042.0          9062.0   \n",
       "...               ...             ...             ...             ...   \n",
       "2022-10-31  19768.458         39687.0         18358.0         18632.0   \n",
       "2022-11-30  19768.458         40049.0         14664.0         17675.0   \n",
       "2022-12-31  19768.458         38650.0         11362.0         16282.0   \n",
       "2023-01-31  19768.458         33983.0          7348.0         14434.0   \n",
       "2023-02-28  19768.458         30697.0         11128.0         12921.0   \n",
       "\n",
       "            PRIREDCOU35620  NEWY636BPPRIV  ...  CUURA101SAR  CUURA101SAF116  \\\n",
       "date                                       ...                                \n",
       "2016-08-31         12840.0         2939.0  ...      118.985         254.813   \n",
       "2016-09-30         11850.0         4275.0  ...      119.552         254.393   \n",
       "2016-10-31         12878.0         4258.0  ...      119.874         254.879   \n",
       "2016-11-30         11808.0         2559.0  ...      120.142         255.126   \n",
       "2016-12-31          9930.0         3483.0  ...      121.092         256.281   \n",
       "...                    ...            ...  ...          ...             ...   \n",
       "2022-10-31          8096.0         3438.0  ...      141.277         296.748   \n",
       "2022-11-30          8752.0         2718.0  ...      144.058         298.499   \n",
       "2022-12-31          7498.0         3549.0  ...      142.249         299.317   \n",
       "2023-01-31          3820.0         4438.0  ...      142.202         302.110   \n",
       "2023-02-28          4626.0         2583.0  ...      144.241         302.161   \n",
       "\n",
       "            CUURA101SAA  CUURA101SANL1  CUURA101SS47016  PSAVERT  MICH  \\\n",
       "date                                                                     \n",
       "2016-08-31      121.576        178.913          194.696      6.8   2.7   \n",
       "2016-09-30      129.847        180.747          188.480      6.8   2.5   \n",
       "2016-10-31      133.232        183.620          190.183      6.8   2.4   \n",
       "2016-11-30      130.743        183.239          192.314      6.9   2.4   \n",
       "2016-12-31      124.428        182.221          202.140      7.0   2.4   \n",
       "...                 ...            ...              ...      ...   ...   \n",
       "2022-10-31      133.312        214.066          313.305      3.0   4.7   \n",
       "2022-11-30      129.743        213.962          304.637      3.4   5.0   \n",
       "2022-12-31      123.985        215.400          323.524      4.1   4.9   \n",
       "2023-01-31      122.084        208.488          302.990      4.4   4.4   \n",
       "2023-02-28      132.814        212.719          297.364      4.4   3.9   \n",
       "\n",
       "            FEDFUNDS  T10Y2Y  T10Y3M  \n",
       "date                                  \n",
       "2016-08-31      0.39    0.79    1.18  \n",
       "2016-09-30      0.40    0.78    1.25  \n",
       "2016-10-31      0.40    0.83    1.31  \n",
       "2016-11-30      0.40    0.98    1.50  \n",
       "2016-12-31      0.41    1.26    1.89  \n",
       "...              ...     ...     ...  \n",
       "2022-10-31      2.56   -0.39    0.50  \n",
       "2022-11-30      3.08   -0.41   -0.12  \n",
       "2022-12-31      3.78   -0.70   -0.69  \n",
       "2023-01-31      4.10   -0.53   -0.54  \n",
       "2023-02-28      4.33   -0.69   -1.18  \n",
       "\n",
       "[77 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('../1. Data Extraction & Cleaning/df.csv')\n",
    "df.date=pd.to_datetime(df.date)\n",
    "df.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a59e206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target variable from the features\n",
    "target = df['RSNA']\n",
    "features = df[['ZABT','ZSFH','NEWY636FIRE','CUURA101SAF11','CUURA101SS47016', 'MICH']]\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "# Put the normalized features and target back into a new DataFrame\n",
    "df_normalized = pd.DataFrame(normalized_features, columns=features.columns)\n",
    "df_normalized['RSNA'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "715afddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df_normalized[['ZABT','ZSFH','NEWY636FIRE','CUURA101SAF11','CUURA101SS47016', 'MICH']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77e86b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d917e8",
   "metadata": {},
   "source": [
    "### Creating Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98974898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:30<00:00, 18.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.15, 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.15, max_depth=2, min_samples_split=4,\n",
       "                          n_estimators=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.15, max_depth=2, min_samples_split=4,\n",
       "                          n_estimators=300)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.15, max_depth=2, min_samples_split=4,\n",
       "                          n_estimators=300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the hyperparameter space to search over\n",
    "param_grid = {'learning_rate': [0.1, 0.15, 0.2],\n",
    "              'n_estimators': [300, 350, 400, 450],\n",
    "              'max_depth': [2, 3, 4],\n",
    "              'min_samples_split': [2, 3, 4],\n",
    "              'min_samples_leaf': [1, 2]}\n",
    "\n",
    "# Create a Gradient Boosting regressor\n",
    "reg = GradientBoostingRegressor()\n",
    "\n",
    "# Run grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(reg, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "for params in tqdm(param_grid):\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "# print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# use the best hyperparameters to create the final model\n",
    "final_model_gb = GradientBoostingRegressor(**grid_search.best_params_)\n",
    "final_model_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25031db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the final model on the testing set\n",
    "y_pred = final_model_gb.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse=math.sqrt(mse)\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "r2 = final_model_gb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7959e3b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.15, 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 300}\n",
      "MAE: 19.74368489544642\n",
      "MSE on testing set: 609.9744919916923\n",
      "RMSE on testing set: 24.697661670524443\n",
      "MAPE: 0.7283330815899238\n",
      "R-squared on testing set: 0.9851086893923215\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE on testing set:\", mse)\n",
    "print(\"RMSE on testing set:\" , rmse)\n",
    "print(\"MAPE:\", mape)\n",
    "print(\"R-squared on testing set:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383ebee9",
   "metadata": {},
   "source": [
    "### Using GBR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c6c402e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [2975.32779671]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnson\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johnson\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### MARCH\n",
    "features = np.array([[367681.3436, 588200.022840, 810.39730, 315.610, 297.364, 3.9]])\n",
    "# Normalize the array\n",
    "normalized_features = scaler.transform(features)\n",
    "prediction = final_model_gb.predict(normalized_features)\n",
    "print(\"Prediction: {}\".format(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "684ba9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70821567, 0.81724657, 0.99335012, 1.        , 0.52356132,\n",
       "        0.54545455]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96927a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [3119.98033685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnson\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johnson\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### APRIL\n",
    "features = np.array([[370384.9491, 588633.772961, 811.15608, 316.115, 296.949,4.1]])\n",
    "normalized_features = scaler.transform(features)\n",
    "prediction = final_model_gb.predict(features)\n",
    "print(\"Prediction: {}\".format(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14bb6c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7266237 , 0.81937782, 1.00785665, 1.00744223, 0.52156582,\n",
       "        0.60606061]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
